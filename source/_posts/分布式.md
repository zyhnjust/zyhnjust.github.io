---
title: 分布式
date: 2018-09-28 15:45:49
tags:
- 面试
---


目标： 基本概念有所了解
- 简单过了一下， 有一些核心还需要继续。 
- 然后第三轮细化。 
<!-- more -->

## next round
下一轮需要看
1 todo
1 分布式事务
- 两阶段  需要理解一下
- 三阶段
- paxos
2 分布式所
- zk
- redis 

# CAP

CAP理论认为，任何联网的共享数据系统只能在三个属性中的两个。但是，通过明确处理分区，设计人员可以优化一致性和可用性，从而实现三者之间的某种权衡。

-》 zk 保证一致性。 保证了 C； 阿里的dubbo 就觉得这种强一致性

Consistency(一致性), 数据一致更新，所有数据变动都是同步的
Availability(可用性), 好的响应性能
Partition tolerance(分区容忍性) 可靠性

BASE模型反ACID模型，完全不同ACID模型，牺牲高一致性，获得可用性或可靠性：
Basically Available基本可用。支持分区失败(e.g. sharding碎片划分数据库)
Soft state软状态 状态可以有一段时间不同步，异步。
Eventually consistent最终一致，最终数据是一致的就可以了，而不是时时高一致。

# BASE

BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。
--》 就是说
基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。

# ACID
Atomicity原子性
Consistency一致性
Isolation隔离性
Durability耐久性


## ACID和BASE的区别与联系
ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。

ACID和BASE代表了两种截然相反的设计哲学

在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用。


## 其他
- READ_UNCOMMITTED
- READ_COMMITTED
- REPETABLE_READ
- SERIALIZABLE
- 
- 脏读
- 非重复读
- Phantom 读

READ_COMMITED 是正确的选择，因为SERIALIZABLE虽然能在不同事务发生时避免stale数据，也就是避免上述丢失刚刚修改的数据，但是性能是最低的，因为是一种最大化的串行。

# 分布式事务

二阶段
一、谈谈业务中使用分布式的场景

业务中使用分布式的场景主要有分布式存储以及分布式计算。

存储 hdfs 

计算 spark

todo 细节

## 一阶段提交， 二阶段？ 

在分布式系统中通常存在着多个机器节点，每个节点只能控制自己事务的成功与失败而无法获知其他节点的事务执行结果，

二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。
所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）

问题： 4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。


举例来说，假设有一个决策小组由一个主持人负责与多位组员以电话联络方式协调是否通过一个提案，以两阶段提交来说，主持人收到一个提案请求，打电话跟每个组员询问是否通过并统计回复，然后将最后决定打电话通知各组员。要是主持人在跟第一位组员通完电话后失忆，而第一位组员在得知结果并执行后老人痴呆，那么即使重新选出主持人，也没人知道最后的提案决定是什么，也许是通过，也许是驳回，不管大家选择哪一种决定，都有可能与第一位组员已执行过的真实决定不一致，老板就会不开心认为决策小组沟通有问题而解雇。三阶段提交即是引入了另一个步骤，主持人打电话跟组员通知请准备通过提案，以避免没人知道真实决定而造成决定不一致的失业危机。为什么能够解决二阶段提交的问题呢？回到刚刚提到的状况，在主持人通知完第一位组员请准备通过后两人意外失忆，即使没人知道全体在第一阶段的决定为何，全体决策组员仍可以重新协调过程或直接否决，不会有不一致决定而失业。那么当主持人通知完全体组员请准备通过并得到大家的再次确定后进入第三阶段，当主持人通知第一位组员请通过提案后两人意外失忆，这时候其他组员再重新选出主持人后，仍可以知道目前至少是处于准备通过提案阶段，表示第一阶段大家都已经决定要通过了，此时便可以直接通过。

## 一致性协议/算法

- 谈谈业务中使用分布式的场景

比如分发。 我们高可用的。 100个任务， 谁拿到谁取。 redis。 
    根据时间。 就拿出来。 
    为什么呢， 因为要均匀。 2两个小时处理10000 任务， 10个来处理这个问题


- 分布式存储

HDFS 数据库， redis， greenplum， 

- 分布式计算
spark么 

- 分布式锁
数据库， 
zk
redis 


分布式锁的场景

只能有一个来做。 那就直接用redis 来做的。 


分布是锁的实现方案
# 分布式session


用的较多的

3.Session集中管理
在单独的服务器或服务器集群上使用缓存技术，如Redis存储Session数据，集中管理所有的Session，所有的Web服务器都从这个存储介质中存取对应的Session，实现Session共享。
优点：可靠性高，减少Web服务器的资源开销。
缺点：实现上有些复杂，配置较多。
适用场景：Web服务器较多、要求高可用性的情况。
可用方案：开源方案Spring Session，也可以自己实现，主要是重写HttpServletRequestWrapper中的getSession方法，博主也动手写了一个，github搜索joincat用户，然后自取。


https://www.jianshu.com/p/3dd4e06bdfa4


五 分布式 Session1. 粘性 Session2. 服务器 Session 复制3. Session 共享机制4. Session 持久化到数据库5. Terracotta 实现 Session 复制

比如集群中存在 A、B 两台服务器，用户在第一次访问网站时，Nginx 通过其负载均衡机制将用户请求转发到 A 服务器，这时 A 服务器就会给用户创建一个 Session。当用户第二次发送请求时，Nginx 将其负载均衡到 B 服务器，而这时候 B 服务器并不存在 Session，所以就会将用户踢到登录页面。这将大大降低用户体验度，导致用户的流失，这种情况是项目绝不应该出现的。


1 粘性

粘性 Session 是指将用户锁定到某一个服务器上，比如上面说的例子，用户第一次请求时，负载均衡器将用户的请求转发到了 A 服务器上，如果负载均衡器设置了粘性 Session 的话，那么用户以后的每次请求都会转发到 A 服务器上，相当于把用户和 A 服务器粘到了一块，这就是粘性 Session 机制。


2. 服务器 Session 复制原理任何一个服务器上的 Session 发生改变，该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要 Session，以此来保证 Session 同步。优点可容错，各个服务器间 Session 能够实时响应。缺点会对网络负荷造成一定压力，如果 Session 量大的话可能会造成网络堵塞，拖慢服务器性能。


Session 共享机制

使用分布式缓存方案比如 Memcached、Redis，但是要求 Memcached 或 Redis 必须是集群。

使用 Session 共享也分两种机制，两种情况如下：

其他 

一、解决java集群的session共享的解决方案：
1.客户端cookie加密。（一般用于内网中企业级的系统中，要求用户浏览器端的cookie不能禁用，禁用的话，该方案会失效）。
2.集群中，各个应用服务器提供了session复制的功能，tomcat和jboss都实现了这样的功能。特点：性能随着服务器增加急剧下降，容易引起广播风暴；session数据需要序列化，影响性能。
3.session的持久化，使用数据库来保存session。就算服务器宕机也没事儿，数据库中的session照样存在。特点：每次请求session都要读写数据库，会带来性能开销。使用内存数据库，会提高性能，但是宕机会丢失数据(像支付宝的宕机，有同城灾备、异地灾备)。
4.使用共享存储来保存session。和数据库类似，就算宕机了也没有事儿。其实就是专门搞一台服务器，全部对session落地。特点：频繁的进行序列化和反序列化会影响性能。
5.使用memcached来保存session。本质上是内存数据库的解决方案。特点：存入memcached的数据需要序列化，效率极低。




# 负载均衡 

- 软件
利用DNS实现负载均衡，就是在DNS服务器配置多个A记录，不同的DNS请求会解析到不同的IP地址。大型网站一般使用DNS作为第一级负载均衡。
缺点是DNS生效时间略长，扩展性差。

基于IP的负载均衡，早期比较有代表性并且被大量使用的的就是LVS了。原理是LVS在Linux内核态获取到IP报文后，根据特定的负载均衡算法将IP报文转发到整个集群的某台服务器中去。缺点是LVS的性能依赖Linux内核的网络性能，但Linux内核的网络路径过长导致了大量开销，使得LVS单机性能较低。

七层的负载均衡有nginx, haproxy, apache等, 工作在应用层,因此可以将HTTP请求等应用数据发送到具体的应用服务器,如将图片请求转发到特定的服务器上


12.4 反向代理负载均衡 -- Nginx？
反向代理服务器的核心工作是转发HTTP，它工作在HTTP层面，因此，基于反向代理的负载均衡也称为七层负载均衡。
任何对于实际服务器的HTTP请求都必须经过调度器；调度器必须等待实际服务器的HTTP响应，并将它反馈给用户。


- 硬件

硬件层的比较牛逼,将4-7层负载均衡功能做到一个硬件里面,如F5,梭子鱼,据说yahoo中国!早些时候只用了两台F5做双活.


说说分库与分表设计 分库与分表带来的分布式困境与应对之策



# 分库与分表带来的分布式困境与应对之策事务问题查询问题ID 唯一性


垂直分表在日常开发和设计中比较常见，通俗的说法叫做“大表拆小表”，拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中，如下图所示：

垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。如下图：


水平分表
水平分表也称为横向分表，比较容易理解，就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行Hash和取模后拆分。如下图所示：
小结
水平分表，能够降低单表的数据量，一定程度上可以缓解查询性能瓶颈。但本质上这些表还保存在同一个库中，所以库级别还是会有IO瓶颈。所以，一般不建议采用这种做法。

垂直分库带来的问题和解决思路：

跨库join的问题
在拆分之前，系统中很多列表和详情页所需的数据是可以通过sql join来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库join的。那该怎么办呢？首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，下面笔者将结合以往的实际经验，总结几种常见的解决思路，并分析其适用场景。



http://www.infoq.com/cn/articles/key-steps-and-likely-problems-of-split-table

# 

zookeeper 是强一致性， 所以dubbo 自己有自己的 是最终一致性


TODO



其他可以看

https://segmentfault.com/q/1010000006095431

1 https://www.jianshu.com/p/1156151e20c8
2 https://juejin.im/entry/5aac6ae55188252c321970e5
。https://juejin.im/post/5ab898b9518825188038eca3

- 面试题目
3 分布式java
https://waylau.gitbooks.io/distributed-java/

4 参考书籍 免费
https://github.com/waylau/books-collection

5 一个项目
https://github.com/codingapi/tx-lcn/wiki/LCN%E5%8E%9F%E7%90%86

目录
https://github.com/Snailclimb/JavaGuide/blob/master/%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F.md

